{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25419b4e",
   "metadata": {},
   "source": [
    "# Information\n",
    "1. This files create a dense vectors (embeddings) from a group of documents\n",
    "2. Stores them in a vector database\n",
    "3. Executes simple test to see if able to be used in conjuction with a LLM\n",
    "\n",
    "Defaults:\n",
    "1. Filetype: .pdf\n",
    "2. Models: text-embedding-3-small & gpt-4-mini"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef715f5",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4218e216",
   "metadata": {},
   "outputs": [],
   "source": [
    "#config\n",
    "import os\n",
    "# FILE_PATH_TO_EMBED = os.path.join(\"pension-martijn-files\", \"Kader Datakwaliteit - wet toekomst pensioenen.pdf.pdf\")\n",
    "DIRECTORY_TO_EMBED = os.path.join(\"pension-martijn-files\")\n",
    "\n",
    "COLLECTION_NAME = \"DATA_QUALITY_PENSION\" #name of the collection\n",
    "PERSIST_DIRECTORY = os.path.join(\"vector_stores\", \"pension-martijn-embeddings\")\n",
    "\n",
    "#os.path.join( \"solvency-II-files\", \"solvency II - level 1 - v2.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6daab6d6",
   "metadata": {},
   "source": [
    "# Embedding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a36cc685",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "\n",
    "# Set your Azure OpenAI credentials\n",
    "embedding_api_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "# print(api_key)\n",
    "\n",
    "# Create an AzureOpenAIEmbeddings object\n",
    "embedding_model = AzureOpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-small\",\n",
    "    azure_endpoint=\"https://openai-playground-bjorn.openai.azure.com/\",\n",
    "    api_version=\"2023-05-15\",\n",
    "    api_key=embedding_api_key\n",
    ")\n",
    "\n",
    "\n",
    "# test out the embedding:\n",
    "\n",
    "# # Create embeddings for some text\n",
    "# text = \"I love learning about computers!\"\n",
    "# text_embeddings = embedding_model.embed_query(text)\n",
    "\n",
    "# # Print the embeddings\n",
    "# print(text_embeddings)\n",
    "# texts = [\"Hello, world!\", \"How are you?\"]\n",
    "# document_embeddings = embeddings.embed_documents(texts)\n",
    "# print(document_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb49bd89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOADED DOCUMENT WITH 130 PAGES\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bvbraak\\AppData\\Local\\Temp\\ipykernel_2388\\1870643632.py:18: UserWarning: DOCUMENT PAGES LOADED IN IS LARGE THAN 100, MAY INCUR SIGNIFICANT COSTS\n",
      "  warnings.warn(\"DOCUMENT PAGES LOADED IN IS LARGE THAN 100, MAY INCUR SIGNIFICANT COSTS\")\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "# load pdf\n",
    "# from langchain_community.document_loaders import PyPDFLoader\n",
    "# loader = PyPDFLoader(FILE_PATH_TO_EMBED)\n",
    "\n",
    "# load directory of PDFs\n",
    "from langchain_community.document_loaders import PyPDFDirectoryLoader\n",
    "loader = PyPDFDirectoryLoader(DIRECTORY_TO_EMBED)\n",
    "\n",
    "pages = []\n",
    "async for page in loader.alazy_load():\n",
    "    pages.append(page)\n",
    "\n",
    "\n",
    "print(f\"LOADED DOCUMENT WITH {len(pages)} PAGES\")\n",
    "if len(pages) > 50:\n",
    "    warnings.warn(\"DOCUMENT PAGES LOADED IN IS LARGE THAN 100, MAY INCUR SIGNIFICANT COSTS\")\n",
    "\n",
    "\n",
    "for page in pages:\n",
    "    if page.page_content == None or page.page_content == \"\":\n",
    "        warnings.warn(\"FOUND PAGES IN DOCUMENT WITHOUT PAGE_CONTENT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "edacea1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "2 \n",
       " \n",
       " \n",
       " \n",
       "Inhoudsopgave  \n",
       "1. INLEIDING KADER DATAKWALITEIT  4 \n",
       "2. OVERZICHT KADER DATAKWALITEIT  8 \n",
       "3. FASE 1: OPZET DATAKWALITEIT  15 \n",
       "3.1 Inleiding  15 \n",
       "3.2 Stappenplan  15 \n",
       "3.2.1 Datakw aliteitsbeleid  15 \n",
       "3.2.2 Kritieke data -elementen (KDE)  15 \n",
       "4. FASE 2: RISICO -INVENTARISATIE EN -BEOORDELING  16 \n",
       "4.1 Inleiding  16 \n",
       "4.2 Stappenpla n 16 \n",
       "4.2.1 Stap 2.1.1: Profiel pensioenuitvoerder  16 \n",
       "4.2.2 Stap 2.1.2: Profiel deelnemers  19 \n",
       "4.2.3 Stap 2.2 Risicobeoordeling  20 \n",
       "4.2.4 Stap 2.3 Vaststellen aanvullende activiteiten  22 \n",
       "5. FASE 3: DATA -ANALYSES EN DEELWAARNEMINGEN  25 \n",
       "5.1 Inleiding  25 \n",
       "5.2 Stappenplan  25 \n",
       "5.2.1 Stap 3.1: Data profiling  25 \n",
       "5.2.2 Stap 3.2.a: Uitvoeren generieke analyses  27 \n",
       "5.2.3 Stap 3.2.b: Bepalen en uitvoeren specifieke analyses  28 \n",
       "5.2.4 Stap 3.3: Deelwaarnemingen  30 \n",
       "6. FASE 4: RAPPORTAGE EN BEOORDELING  33 \n",
       "6.1 Inleiding  33 \n",
       "6.2 Stappenplan  33 \n",
       "6.2.1 Stap 4.1: Rapportage en beoordeling  33 \n",
       "6.2.2 Stap 4.2: Besluitvorming  34 \n",
       "6.2.3 Stap 4.3: Correcties uitvoeren  35 \n",
       "6.2.4 Stap 4.4: Voorlopig oordeel bestuur over de datakwaliteit  36"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "Markdown(pages[1].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ee45a4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': None,\n",
       " 'metadata': {'producer': 'Microsoft® Word voor Microsoft 365',\n",
       "  'creator': 'Microsoft® Word voor Microsoft 365',\n",
       "  'creationdate': '2022-10-23T18:44:56+02:00',\n",
       "  'author': 'Otto Hulst',\n",
       "  'moddate': '2022-10-23T18:44:56+02:00',\n",
       "  'source': 'pension-martijn-files\\\\Kader Datakwaliteit - wet toekomst pensioenen.pdf.pdf',\n",
       "  'total_pages': 61,\n",
       "  'page': 10,\n",
       "  'page_label': '11'},\n",
       " 'page_content': '11 \\n \\n \\n \\nIn onderstaand schema wordt iedere stap per fase kort toegelicht om een beeld te \\ngeven van de reeks van werkzaamheden ten behoeve van het aantoonbaar toetsen van \\ndatakwaliteit vóór het invaren. Vanaf hoofdstuk 3 zullen de stappen per fase één voor \\néén uitgebreider worden toegelicht door in te gaan op de benodigdheden voor de stap \\nen de uit te voeren activiteiten. Hierbij wordt door de pensioenuitvoerder elke stap \\ndoorlopen en de uitvoering en uitkomsten daarvan worden gedocumenteerd. Op basis \\nvan het principe ‘comply or explain’ kan de pensioenuitvoerder onderbouwen waarom \\nbepaalde werkzaamheden eventueel niet of niet volledig worden uitgevoerd. Ook is het \\nmogelijk dat de pensioenuitvoerder vaststelt dat aanvullende werkzaamheden (anders \\ndan die beschreven in dit kader) nodig zijn om tot het oordeel te komen dat de data in \\nde pensioenadministratie van voldoende kwaliteit is vóór het invaren. \\n# Naam Toelichting \\nFASE 1 Opzet datakwaliteit \\nStap 1.1 Datakwaliteitsbeleid \\n \\nOm de fase van de opzet van datakwaliteit af te ronden, worden \\ntwee stappen doorlopen. De eerste stap is het vaststellen of het \\nonderdeel ‘risicobereidheid’ (1.1.a) is opgenomen in het \\ndatakwaliteitsbeleid. Ook wordt vastgesteld of een ‘correctie-\\n/herzieningenbeleid’ (1.1.b) is opgesteld. Voor beide onderdelen \\n(1.1.a en 1.1.b) wordt vervolgens vastgesteld of deze actueel en \\nbruikbaar zijn voor het doel van dit kader. Beiden vormen de basis \\nvoor de volgende stappen.  \\nStap 1.2 Kritieke data-\\nelementen (KDE) \\nIn de tweede stap worden de KDE’s vastgesteld die op de \\npensioenuitvoerder van toepassing zijn. Zie bijlage A.4 voor \\nvoorbeeld KDE’s. \\nFASE 2 Risico-inventarisatie en -beoordeling \\nStap 2.1 Risico-inventarisatie  \\nStap \\n2.1.1 \\nProfiel \\npensioenuitvoerder \\nIn deze stap wordt een onderbouwde inschatting gemaakt van het \\nrisicoprofiel van de pensioenuitvoerder. Deze inschatting start \\nvanuit:  \\na. Risico-indicatoren vanuit het profiel en de kenmerken van \\nde pensioenuitvoerder. Vaststellen van de algemene \\nrisico’s van de pensioenuitvoerder op basis van \\nverschillende indicatoren (zie bijlage A.1). \\nb. Risico-indicatoren vanuit het \\ndatakwaliteitsbeheersingsraamwerk (zie bijlage A.2) en de \\ndatastromen in processen; met aandacht voor systemen, \\nmigraties en bevindingen/tekortkomingen uit \\nonderzoeken.  \\nc. Risico-indicatoren vanuit events. De pensioenuitvoerder \\ninventariseert welke events zich hebben voorgedaan die \\nvan invloed zijn op de datakwaliteit en de beschikbaarheid \\nvan de data, zoals bijvoorbeeld: collectieve \\nwaardeoverdrachten, migraties en implementaties.',\n",
       " 'type': 'Document'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages[10].__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb5beea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DOCUMENT WITH 130 PAGES\n",
      "NUMBER OF CHUNKS: 372\n"
     ]
    }
   ],
   "source": [
    "#for brevity we will drop a few pages from solvency II to test embedding cost for cheap model\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "print(f\"DOCUMENT WITH {len(pages)} PAGES\")\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,   # Each chunk will be 1000 characters\n",
    "    chunk_overlap=100  # Overlap of 100 characters between chunks\n",
    ")\n",
    "\n",
    "split_pages = text_splitter.transform_documents(pages)\n",
    "\n",
    "print(f\"NUMBER OF CHUNKS: {len(split_pages)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c059068a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "from langchain_chroma import Chroma\n",
    "vectorstore = Chroma(COLLECTION_NAME, embedding_model, persist_directory=PERSIST_DIRECTORY)\n",
    "print(vectorstore._collection.count())\n",
    "# test_vectorstore = Chroma.from_documents(split_pages[:3], embedding_model, collection_name=COLLECTION_NAME, persist_directory=PERSIST_DIRECTORY)\n",
    "# print(test_vectorstore._collection.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a37b9f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATING A NEW VECTOR STORE AT SPECIFIED LOCATION\n",
      "372\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "# In memory vector store for testing only\n",
    "# vectorstore = InMemoryVectorStore(embedding_model)\n",
    "# create a database with vector embedding and documents.\n",
    "\n",
    "# note: behavior of from_documents is to add if vectorstore already exists\n",
    "delete_vector_store_check = input(\"Do you want to delete the vector_store before adding these documents?\")\n",
    "if delete_vector_store_check == \"Y\":\n",
    "    Chroma.delete_collection(Chroma(COLLECTION_NAME, embedding_model, persist_directory=PERSIST_DIRECTORY))\n",
    "\n",
    "# Save a new vector store based on config at top of this file (create_vector_store.ipynb)\n",
    "check = input(\"Are you sure you want to run this command? Creating a vectorstore will append to the existing vectorstore and may incur high costs (Y/n)\")\n",
    "\n",
    "if check == \"Y\":\n",
    "    print(\"CREATING A NEW VECTOR STORE AT SPECIFIED LOCATION\")\n",
    "    vectorstore = Chroma.from_documents(split_pages, embedding_model, collection_name=COLLECTION_NAME, persist_directory=PERSIST_DIRECTORY)\n",
    "    print(vectorstore._collection.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1f6746",
   "metadata": {},
   "source": [
    "# LLM\n",
    "Test Cases for embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bb7f793e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "654\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "\n",
    "# setup the llm\n",
    "llm_api_key = os.getenv(\"GPT_4O_MINI_API_KEY\")\n",
    "# print(llm_api_key)\n",
    "llm = AzureChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    azure_endpoint=\"https://openai-playground-bjorn.openai.azure.com/\",\n",
    "    api_version=\"2025-01-01-preview\",\n",
    "    api_key=llm_api_key\n",
    ")\n",
    "\n",
    "# load the vectorstore\n",
    "from langchain_chroma import Chroma\n",
    "vectorstore = Chroma(COLLECTION_NAME, embedding_model, persist_directory=PERSIST_DIRECTORY)\n",
    "print(vectorstore._collection.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5fc56cb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First documents of all matched documents: {'id': '684ca3a6-d6bd-41c5-ba08-89d8b23ea302', 'metadata': {'author': 'Otto Hulst', 'creationdate': '2022-10-23T18:44:56+02:00', 'creator': 'Microsoft® Word voor Microsoft 365', 'moddate': '2022-10-23T18:44:56+02:00', 'page': 32, 'page_label': '33', 'producer': 'Microsoft® Word voor Microsoft 365', 'source': 'pension-martijn-files\\\\Kader Datakwaliteit - wet toekomst pensioenen.pdf.pdf', 'total_pages': 61}, 'page_content': '33 \\n \\n \\n \\n6. Fase 4: Rapportage en beoordeling \\n \\n6.1 Inleiding \\nOp basis van de resultaten uit de vorige fasen wordt een rapportage opgesteld door \\nde pensioenuitvoerder conform de daarvoor binnen de pensioenuitvoerder \\nvastgestelde governance, waarbij sleutelhouders expliciet worden betrokken. De \\nrapportage wordt vervol gens beoordeeld door het bestuur. Het kader onderscheidt \\nvoor deze fase de volgende vier stappen:  \\n \\n1. Rapportage en evaluatie van fase 2 en 3.  \\n2. Beoordeling en besluitvorming door het bestuur aan de hand van de \\nrapportage.  \\n3. De benodigde correcties die in vorige stappen vastgesteld zijn , worden in \\ndeze stap onderzocht op grondoorzaak (incidenteel/structureel), \\ngecorrigeerd  en gedocumenteerd.  \\n4. Het bestuur geeft een voorlopig oordeel af over de datakwaliteit.  \\n \\n6.2 Stappenplan \\n \\n \\n \\n6.2.1 Stap 4.1: Rapportage en beoordeling \\nBenodigdheden  \\nDe resultaten van de risicobeoordeling (fase 2) en de uitgevoerde data -analyses en', 'type': 'Document'}\n",
      "['pension-martijn-files\\\\Kader Datakwaliteit - wet toekomst pensioenen.pdf.pdf']\n",
      "\n",
      "    source 0:\n",
      "    33 \n",
      " \n",
      " \n",
      " \n",
      "6. Fase 4: Rapportage en beoordeling \n",
      " \n",
      "6.1 Inleiding \n",
      "Op basis van de resultaten uit de vorige fasen wordt een rapportage opgesteld door \n",
      "de pensioenuitvoerder conform de daarvoor binnen de pensioenuitvoerder \n",
      "vastgestelde governance, waarbij sleutelhouders expliciet worden betrokken. De \n",
      "rapportage wordt vervol gens beoordeeld door het bestuur. Het kader onderscheidt \n",
      "voor deze fase de volgende vier stappen:  \n",
      " \n",
      "1. Rapportage en evaluatie van fase 2 en 3.  \n",
      "2. Beoordeling en besluitvorming door het bestuur aan de hand van de \n",
      "rapportage.  \n",
      "3. De benodigde correcties die in vorige stappen vastgesteld zijn , worden in \n",
      "deze stap onderzocht op grondoorzaak (incidenteel/structureel), \n",
      "gecorrigeerd  en gedocumenteerd.  \n",
      "4. Het bestuur geeft een voorlopig oordeel af over de datakwaliteit.  \n",
      " \n",
      "6.2 Stappenplan \n",
      " \n",
      " \n",
      " \n",
      "6.2.1 Stap 4.1: Rapportage en beoordeling \n",
      "Benodigdheden  \n",
      "De resultaten van de risicobeoordeling (fase 2) en de uitgevoerde data -analyses en\n",
      "\n",
      "    \n",
      "Based the above mentioned sources, can you provide an answer on the following question?\n",
      "Question: kan je mij een introductie geven tot fase 4: rapportage en beoordeling\n",
      "Answer: \n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"kan je mij een introductie geven tot fase 4: rapportage en beoordeling\"\n",
    "matched_documents = vectorstore.similarity_search(query=query,k=1)\n",
    "\n",
    "print(f\"First documents of all matched documents: {matched_documents[0].__dict__}\")\n",
    "\n",
    "prompt = \"\"\n",
    "document_source = []\n",
    "for idx, document in enumerate(matched_documents):\n",
    "    document_source.append(document.metadata[\"source\"])\n",
    "    prompt += f\"\"\"\n",
    "    source {idx}:\n",
    "    {document.page_content}\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "print(document_source)\n",
    "# print(prompt)\n",
    "\n",
    "prompt += f\"\"\"\n",
    "Based the above mentioned sources, can you provide an answer on the following question?\n",
    "Question: {query}\n",
    "Answer: \n",
    "\"\"\"\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "106b9035",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ce8a0ccf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Fase 4 van het proces betreft de rapportage en beoordeling, waarbij de focus ligt op het organiseren van de bevindingen uit de eerdere fasen van het project. In deze fase stelt de pensioenuitvoerder een rapport op dat is gebaseerd op de resultaten uit fase 2 en fase 3. Dit rapport wordt opgesteld volgens de vastgestelde governance-structuur binnen de pensioenuitvoerder, waarbij betrokkenheid van sleutelhouders is gegarandeerd. \n",
       "\n",
       "De fase omvat vier belangrijke stappen: \n",
       "\n",
       "1. De rapportage en evaluatie van de resultaten uit fase 2 en 3.\n",
       "2. De beoordeling en besluitvorming door het bestuur op basis van de gepresenteerde rapportage.\n",
       "3. Het onderzoeken, corrigeren en documenteren van benodigde aanpassingen die in eerdere fasen zijn vastgesteld, met een focus op de oorzaak van de problemen (incidenteel of structureel).\n",
       "4. Een voorlopig oordeel van het bestuur over de kwaliteit van de aanwezige data.\n",
       "\n",
       "Deze fase is cruciaal voor het waarborgen van de integriteit en betrouwbaarheid van de gegevens en de aanpassing van de processen op basis van gedetailleerde analyses en bestuurlijke beoordeling."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "Markdown(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ac8c0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RegulationSearch-Demo",
   "language": "python",
   "name": "regulationsearch-demo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
